# ü©∫ MLOps Pipeline Design -> Predictor M√©dico  -> V1.0.1  



Este servicio implementa una **simulaci√≥n de modelo de predicci√≥n m√©dica**, que recibe tres valores cl√≠nicos (`fiebre`, `presion`, `frecuencia_cardiaca`) y determina un posible estado de salud del paciente seg√∫n reglas predefinidas.  

El sistema **no utiliza un modelo de Machine Learning real**, sino que emula la l√≥gica de decisi√≥n de un sistema de diagn√≥stico automatizado, devolviendo una de las siguientes cinco categor√≠as:

- `NO ENFERMO`  
- `ENFERMEDAD LEVE`  
- `ENFERMEDAD AGUDA`  
- `ENFERMEDAD CR√ìNICA`  
- `ENFERMEDAD TERMINAL`  

Adem√°s, el servicio mantiene un registro persistente de las predicciones realizadas y permite obtener un **reporte estad√≠stico** con la siguiente informaci√≥n:
- N√∫mero total de predicciones por categor√≠a.  
- Las √∫ltimas 5 predicciones realizadas.  
- Fecha y hora de la √∫ltima predicci√≥n.


## üìÅ Estructura del Proyecto  

```
Taller_Semana1/
‚îÇ
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py           # Indica que 'app' es un paquete Python
‚îÇ   ‚îú‚îÄ‚îÄ main.py               # API Flask que expone los endpoints
‚îÇ   ‚îú‚îÄ‚îÄ model.py              # Funci√≥n de predicci√≥n simulada + registro
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt      # Dependencias del proyecto
‚îÇ   ‚îî‚îÄ‚îÄ tests/
‚îÇ       ‚îî‚îÄ‚îÄ test_model.py     # Pruebas unitarias para el pipeline CI/CD
‚îÇ
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ ci_cd_pipeline.yaml  # Pipeline CI/CD con GitHub Actions
‚îÇ
‚îú‚îÄ‚îÄ Dockerfile                # Construcci√≥n de la imagen Docker
‚îî‚îÄ‚îÄ README.md                 # Documentaci√≥n del proyecto
```

## 1. Supuestos Generales

### Sobre el usuario (m√©dico)

* Puede ejecutar el servicio localmente usando Docker, conforme a tu implementaci√≥n actual.

* Tambi√©n puede consumir una API REST si la versi√≥n final se despliega en la nube.

* No necesita habilidades t√©cnicas avanzadas.

### Sobre los datos

* Valores cl√≠nicos tabulares:
fiebre, presion, frecuencia_cardiaca.

* Para efectos del proyecto, el modelo es simulado, pero el pipeline se dise√±a como si fuese un ML real.

* Enfermedades comunes y hu√©rfanas deber√°n manejar distinto volumen de datos.

### Sobre privacidad

Los datos procesados deben ser anonimizados.

No se almacenan datos sensibles en BD ‚Üí √∫nicamente logs locales JSONL (predicciones.log).

### Sobre la infraestructura

* El pipeline permite ejecuci√≥n:

  * Local (Docker + Flask)

  * Cloud (API gateway + Docker + servidor REST)

  * Desarrollo continuo via CI/CD

## 2. Pipeline de MLOps

A continuaci√≥n se describe el proceso completo end-to-end.

### Ingesta de Datos

* La ingesta proviene de registros que el m√©dico ingresa manualmente mediante una solicitud HTTP.

* En un entorno real, vendr√≠an de EHR, HL7, FHIR o CSV cl√≠nicos.


### Validacion y Calidad de Los Datos.

* La API debe validar:

  * Tipos num√©ricos

  * Rango fisiol√≥gico aceptable

### Almacenamiento y Versionamiento de los Datos.

Actualmente:

* Se registra cada predicci√≥n en predicciones.log en formato JSONL

En PROD, se recomienda:

* Data Lake ‚Üí MinIO o S3

* Versionado ‚Üí DVC

### Feature Engineering.

Actualmente: Se Simula la cosntruccion de los puntajes.

En PROD, se recomienda:

* Imputaci√≥n de faltantes

* Normalizaci√≥n

* Selecci√≥n de features

* Feature Store: Feast

### Entrenamiento del Modelo.

### Validacion del Modelo.

Para evaluar:

* Accuracy

* F1

* ROC-AUC

* PR-AUC (hu√©rfanas)

Actualmente:

* Las pruebas unitarias validan que el modelo responda a las solicitudes Http, de froma correcta.

### Registro del Modelo.

Se deberia usar:

* MLflow Model Registry

* Control de versiones

* Promoci√≥n de modelos a producci√≥n

### CI/CD Testing.
 - **Pruebas unitarias** (`pytest`) ejecutadas en GitHub Actions.  

  - **Comentarios autom√°ticos** en Pull Requests. 

### Empaquetado y Despliegue.

Despliegue local v√≠a Dockerfile (archivo actualizado):

* Flask

* Puerto 5000 ‚Üí Mapeado a 5001

Propuesta extendida:

* AWS ECS, Azure Container Apps o GCP Cloud Run

* API REST Flask/FastAPI 

### Monitoreo en Produccion.

Se recomienda:

* EvidentlyAI ‚Üí Data drift

* Prometheus + Grafana ‚Üí M√©tricas de API

* Loki ‚Üí Logs centralizados

### Reentrenamiento Automatizado.

Cuando:

* Se Detecte Drift detectado

* Nuevo dataset cargado

* Validaci√≥n m√©dica

Tecnolog√≠a recomendada:

* Airflow


## 3. Dise√±o del  Pipeline

![This is an alt text.](/imgs/DIse√±oMlOPS.drawio.png "This is a sample image.")



## 4. Stack Tecnologico

| Etapa        | Tecnolog√≠a                        | Justificaci√≥n                      |
| ------------ | --------------------------------- | ---------------------------------- |
| API          | Flask                             | Ligero, simple, ya implementado    |
| L√≥gica       | Python 3.10                       | Base del proyecto                  |
| Modelo       | Reglas simuladas (actual)         | Requerido en entregable            |
| Logging      | JSONL local                       | Cumple requerimiento /reporte      |
| Testing      | Pytest                            | Integrado en tu c√≥digo             |
| CI/CD        | GitHub Actions                    | Pipeline reproducible              |
| Contenedores | Docker                            | Permite ejecuci√≥n local y en cloud |
| Monitoreo    | (Propuesto) Prometheus, Evidently | Requisito de MLOps                 |
| Orquestaci√≥n | (Propuesto) Airflow               | Para retraining futuro             |


## 5. Changelog

| Componente    | Semana 1            | Versi√≥n Final (actual, tus archivos)                               |
| ------------- | ------------------- | ------------------------------------------------------------------ |
| Predicci√≥n    | Funci√≥n simple      | Funci√≥n con c√°lculo escalar y 5 niveles de enfermedad              |
| Logging       | No exist√≠a          | Archivo JSONL `predicciones.log` generado autom√°ticamente          |
| Endpoints     | S√≥lo `/predecir`    | Ahora `/` y `/reporte` incluidos                                   |
| CI/CD         | No exist√≠a          | Pipeline integrado de pruebas (Github Actions declarado en README) |
| Testing       | No exist√≠a          | `tests/test_model.py` creado con dos pruebas unitarias reales      |
| Documentaci√≥n | README b√°sico       | README completo con endpoints y logs                               |
| Arquitectura  | Sin pipeline formal | Pipeline MLOps completo incorporado                                |
| Despliegue    | Docker simple       | Docker + API + preparaci√≥n para cloud                              |
| Monitoreo     | No exist√≠a          | Propuesto: Prometheus + EvidentlyAI                                |
| Ingenier√≠a    | Nivel b√°sico        | Redacci√≥n profesional alineada a MLOps                             |



---

## üß± Construcci√≥n de la imagen Docker

```bash
docker build -t taller_semana1 .
```

---

## üöÄ Ejecuci√≥n del servicio

```bash
docker run -d -p 5001:5000 taller_semana1
```

El servicio quedar√° disponible en:  
üëâ `http://localhost:5001`

---

## üß™ Ejemplo de uso del modelo  

Puede enviar una solicitud `POST` al endpoint `/predecir` con los tres valores de entrada (por ejemplo, s√≠ntomas simulados):  

```bash
curl -X POST -H "Content-Type: application/json"   -d '{"fiebre": 38, "presion": 120, "frecuencia_cardiaca": 90}'   http://localhost:5001/predecir
```

**Respuesta esperada:**
```json
{
  "resultado": "ENFERMEDAD AGUDA"
}
```

---

## üìä Obtener reporte de predicciones

El sistema genera autom√°ticamente un archivo `predicciones.log` con todas las solicitudes realizadas.  
Para acceder al resumen estad√≠stico, puede consultarse el endpoint `/reporte`:

```bash
curl -X GET http://localhost:5001/reporte
```

**Ejemplo de respuesta:**
```json
{
  "total_por_categoria": {
    "ENFERMEDAD AGUDA": 3,
    "ENFERMEDAD LEVE": 1
  },
  "ultimas_5_predicciones": [
    {"fecha": "2025-11-14 22:31:10", "fiebre": 38, "presion": 120, "frecuencia_cardiaca": 90, "resultado": "ENFERMEDAD AGUDA"}
  ],
  "ultima_fecha": "2025-11-14 22:31:10"
}
```

---


---

## üí° Notas T√©cnicas  

- Desarrollado en **Python 3.10** utilizando **Flask** como framework web.  
- La API expone dos rutas principales:
  - `POST /predecir` ‚Üí recibe tres valores y devuelve la predicci√≥n.  
  - `GET /reporte` ‚Üí muestra estad√≠sticas acumuladas de predicciones.  
- El contenedor expone el **puerto 5000 interno**, mapeado al **5001 local**.  
- El archivo de registro `predicciones.log` se crea autom√°ticamente en el contenedor.  
- Para detener el contenedor en ejecuci√≥n:
  ```bash
  docker ps        # Identificar el ID del contenedor
  docker stop <ID> # Detener el contenedor
  ```
- Pipeline CI/CD automatizado con:
  - **Pruebas unitarias** (`pytest`) ejecutadas en GitHub Actions.  
  - **Comentarios autom√°ticos** en Pull Requests.  

